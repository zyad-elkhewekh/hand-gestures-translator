{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-23T18:10:26.484459Z",
     "start_time": "2025-08-23T18:10:20.587800Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T18:10:31.288949Z",
     "start_time": "2025-08-23T18:10:29.217590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dir = \"D:/robo-sumr-2025/project/data/asl_alphabet_train\"\n",
    "val_dir   = \"D:/robo-sumr-2025/project/data/asl_alphabet_test\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128, 128),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_generator = test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(128, 128),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\"\n",
    ")\n"
   ],
   "id": "84d0229628adbdae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67200 images belonging to 28 classes.\n",
      "Found 28 images belonging to 28 classes.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T18:11:27.578593Z",
     "start_time": "2025-08-23T18:11:25.753018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from keras.src.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(128,128,3))\n",
    "base_model.trainable = False\n"
   ],
   "id": "dd97a0858cad95a9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T18:11:30.285771Z",
     "start_time": "2025-08-23T18:11:30.156349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten,GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "preds = Dense(train_generator.num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=preds)\n"
   ],
   "id": "7987fdd5c16cd66a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T18:11:31.910914Z",
     "start_time": "2025-08-23T18:11:31.884717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n"
   ],
   "id": "48deed8872f6c14a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T20:01:08.343494Z",
     "start_time": "2025-08-23T18:11:34.087067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10\n",
    ")\n"
   ],
   "id": "da6a6ad882fc0940",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2100/2100 [==============================] - 626s 296ms/step - loss: 2.5410 - accuracy: 0.3050 - val_loss: 0.5926 - val_accuracy: 0.8571\n",
      "Epoch 2/10\n",
      "2100/2100 [==============================] - 641s 305ms/step - loss: 1.4297 - accuracy: 0.5705 - val_loss: 0.3211 - val_accuracy: 0.9286\n",
      "Epoch 3/10\n",
      "2100/2100 [==============================] - 739s 352ms/step - loss: 1.1242 - accuracy: 0.6624 - val_loss: 0.2304 - val_accuracy: 0.9643\n",
      "Epoch 4/10\n",
      "2100/2100 [==============================] - 722s 344ms/step - loss: 0.9815 - accuracy: 0.7039 - val_loss: 0.1770 - val_accuracy: 0.9643\n",
      "Epoch 5/10\n",
      "2100/2100 [==============================] - 671s 319ms/step - loss: 0.8961 - accuracy: 0.7303 - val_loss: 0.1674 - val_accuracy: 0.9286\n",
      "Epoch 6/10\n",
      "2100/2100 [==============================] - 691s 329ms/step - loss: 0.8445 - accuracy: 0.7453 - val_loss: 0.1377 - val_accuracy: 0.9643\n",
      "Epoch 7/10\n",
      "2100/2100 [==============================] - 713s 339ms/step - loss: 0.8051 - accuracy: 0.7571 - val_loss: 0.1487 - val_accuracy: 0.9643\n",
      "Epoch 8/10\n",
      "2100/2100 [==============================] - 589s 280ms/step - loss: 0.7795 - accuracy: 0.7646 - val_loss: 0.1367 - val_accuracy: 0.9643\n",
      "Epoch 9/10\n",
      "2100/2100 [==============================] - 563s 268ms/step - loss: 0.7624 - accuracy: 0.7677 - val_loss: 0.1350 - val_accuracy: 0.9643\n",
      "Epoch 10/10\n",
      "2100/2100 [==============================] - 620s 295ms/step - loss: 0.7404 - accuracy: 0.7763 - val_loss: 0.1252 - val_accuracy: 0.9643\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T20:05:03.390537Z",
     "start_time": "2025-08-23T20:05:03.195899Z"
    }
   },
   "cell_type": "code",
   "source": "model.save(\"my_final_model.h5\")",
   "id": "5a10e9b1191b5964",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T20:03:49.572509Z",
     "start_time": "2025-08-23T20:03:48.262133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(\"my_final_model.h5\")"
   ],
   "id": "54edef142c90e637",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T20:04:56.533042Z",
     "start_time": "2025-08-23T20:04:56.525074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#########################\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "class_labels = list(train_generator.class_indices.keys())\n",
    "\n",
    "def predict_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(128,128))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    preds = model.predict(img_array)\n",
    "    predicted_class = np.argmax(preds, axis=1)[0]\n",
    "    confidence = np.max(preds)\n",
    "\n",
    "    return class_labels[predicted_class], confidence\n"
   ],
   "id": "d0c05ff20b6725f7",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T20:04:58.496183Z",
     "start_time": "2025-08-23T20:04:57.251111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_img = \"D:/robo-sumr-2025/project/data/asl_alphabet_test/X/X_test.jpg\"\n",
    "\n",
    "test_img2 = \"C:/Users/zyads/Desktop/A.jpeg\"\n",
    "\n",
    "label, conf = predict_image(test_img2)\n",
    "print(f\"Predicted: {label} ({conf*100:.2f}% confidence)\")\n"
   ],
   "id": "6ec2185f7b58ec05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted: T (53.58% confidence)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ad414deb1128a1ca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
